use chrono::DateTime;
// src/log_worker.rs
use clap::Parser;
use deadpool_redis::{Config as RedisPoolConfig, Runtime};
use kafka_demo::common::SeckillRecord;
use kafka_demo::redis_state::pop_log_detail;
use serde::Deserialize;
use sqlx::postgres::PgPoolOptions;
use sqlx::QueryBuilder;
use std::sync::Arc;
use std::time::Duration;
use tokio::time::{sleep, Instant};

/// æ—¥å¿—è½åº“ Workerï¼ˆæ¶ˆè´¹ logs:detailï¼‰
#[derive(Parser, Debug, Clone, Deserialize, Default)]
#[serde(default)]
#[command(author, version, about)]
struct Args {
    #[arg(long)]
    redis_url: Option<String>,

    #[arg(long)]
    pg_dsn: Option<String>,
}

#[derive(Debug, Deserialize)]
struct Config {
    log_worker: Option<Args>,
    server: Args,
}

#[allow(dead_code)]
#[tokio::main]
async fn main() {
    let mut args = Args::parse();

    // åˆå¹¶ config.yaml
    let config_path = std::env::current_dir().unwrap().join("config.yaml");
    if config_path.exists() {
        if let Ok(file) = std::fs::File::open(config_path) {
            if let Ok(config) = serde_yaml::from_reader::<_, Config>(file) {
                let fallback = config.log_worker.unwrap_or(config.server);
                args.redis_url = args.redis_url.or(fallback.redis_url);
                args.pg_dsn = args.pg_dsn.or(fallback.pg_dsn);
            }
        }
    }

    let args_redis_url = args.redis_url.expect("Missing --redis-url or config.log_worker.redis_url");
    let args_pg_dsn = args.pg_dsn.expect("Missing --pg-dsn or config.log_worker.pg_dsn");

    let redis_cfg = RedisPoolConfig::from_url(args_redis_url);
    let redis_pool = Arc::new(
        redis_cfg
            .create_pool(Some(Runtime::Tokio1))
            .expect("Failed to create Redis pool"),
    );

    let pg_pool = PgPoolOptions::new()
        .max_connections(5)
        .connect(&args_pg_dsn)
        .await
        .expect("PostgreSQL connect fail");

    println!("[LogWorker] å¯åŠ¨æˆåŠŸ");

    // æ‰¹é‡çª—å£å‚æ•°
    const BATCH_SIZE: usize = 100;
    const BATCH_INTERVAL_MS: u64 = 10_000; // 10 ç§’
    const STATUS_REPORT_INTERVAL_MS: u64 = 60_000; // æ¯ 60 ç§’è¾“å‡ºä¸€æ¬¡çŠ¶æ€

    let mut batch = Vec::with_capacity(BATCH_SIZE);
    let mut last_flush = Instant::now();
    let mut last_status_report = Instant::now(); // ğŸ’¡ æ–°å¢çŠ¶æ€æŠ¥å‘Šæ—¶é—´è®°å½•

    loop {
        let mut did_pop = false;

        // ä¸€è½®å°½é‡å¡«æ»¡ batch
        for _ in 0..(BATCH_SIZE - batch.len()) {
            if let Some(json) = pop_log_detail(&redis_pool, 2).await {
                did_pop = true;
                println!("[LogWorker] pop -> {}", json);
                match serde_json::from_str::<SeckillRecord>(&json) {
                    Ok(rec) => batch.push(rec),
                    Err(e) => eprintln!("[LogWorker] âŒ JSON è§£æå¤±è´¥: {e}"),
                }
            } else {
                break;
            }
        }

        let time_due = last_flush.elapsed() >= Duration::from_millis(BATCH_INTERVAL_MS);
        let size_due = batch.len() >= BATCH_SIZE;

        if !batch.is_empty() && (size_due || time_due) {
            println!("[LogWorker] flush batch: {} æ¡ï¼Œè·ç¦»ä¸Šæ¬¡å†™å…¥ {:?}", batch.len(), last_flush.elapsed());
            match insert_batch(&pg_pool, &batch).await {
                Ok(_) => println!("[LogWorker] âœ… æ‰¹é‡å†™å…¥ {} æ¡", batch.len()),
                Err(e) => eprintln!("[LogWorker] âŒ å†™å…¥å¤±è´¥: {e}"),
            }
            batch.clear();
            last_flush = Instant::now();
        }

        // æ²¡æœ‰æ–°æ•°æ®å°± sleepï¼Œé¿å…ç©ºè½¬
        if !did_pop {
            sleep(Duration::from_millis(200)).await;
        }
        
        // å®šæœŸçŠ¶æ€æ—¥å¿—ï¼ˆå¦‚å¿ƒè·³ï¼‰
        if last_status_report.elapsed() >= Duration::from_millis(STATUS_REPORT_INTERVAL_MS) {
            println!(
                "[LogWorker] ğŸŸ¢ çŠ¶æ€æŠ¥å‘Šï¼šå½“å‰ batch ä¸­æœ‰ {} æ¡æ•°æ®ï¼ŒRedisè¿æ¥çŠ¶æ€: {:?}",
                batch.len(),
                redis_pool.status()
            );
            last_status_report = Instant::now();
        }
    }
}

async fn insert_batch(pool: &sqlx::PgPool, records: &[SeckillRecord]) -> Result<(), sqlx::Error> {
    println!("[LogWorker] ğŸ”¨ æ‰¹é‡æ„å»º INSERT è¯­å¥: {} æ¡", records.len());

    let mut tx = pool.begin().await?;

    let mut builder = QueryBuilder::new(
        "INSERT INTO seckill_record (user_id, activity_id, cost_ms, status, ts) ",
    );

    builder.push_values(records, |mut b, r| {
        b.push_bind(r.user_id as i64)
            .push_bind(r.activity_id as i64)
            .push_bind(r.cost_ms as i32)
            .push_bind(&r.status)
            .push_bind(DateTime::from_timestamp(
                r.timestamp as i64,
                0,
            ).unwrap_or_else(|| {
                eprintln!("[LogWorker] âš ï¸ timestamp éæ³•å€¼: {}", r.timestamp);
                DateTime::from_timestamp(0, 0)
                    .expect("timestamp 0 ç«Ÿç„¶ä¸åˆæ³•")
            }));
    });

    builder.build().execute(&mut *tx).await?;
    tx.commit().await?;

    Ok(())
}